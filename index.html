<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
    <!-- Replace the content tag with appropriate information -->
    <meta name="description"
        content="Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers">
    <meta property="og:title" content="Look, Focus, Act" />
    <meta property="og:description"
        content="Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers" />
    <meta property="og:url" content="https://ian-chuang.github.io/gaze-av-aloha/" />
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
    <meta property="og:image" content="static/image/your_banner_image.png" />
    <meta property="og:image:width" content="1200" />
    <meta property="og:image:height" content="630" />


    <meta name="twitter:title" content="Look, Focus, Act">
    <meta name="twitter:description"
        content="Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers">
    <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
    <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
    <meta name="twitter:card" content="summary_large_image">
    <!-- Keywords for your paper to be indexed by-->
    <meta name="keywords" content="Imitation Learning, Foveated Vision, Bimanual Manipulation">
    <meta name="viewport" content="width=device-width, initial-scale=1">


    <title>Look, Focus, Act: Efficient and Robust Robot Learning via Human Gaze and Foveated Vision Transformers</title>
    <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="static/css/bulma.min.css">
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="static/css/index.css">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
    <script defer src="static/js/fontawesome.all.min.js"></script>
    <script src="static/js/bulma-carousel.min.js"></script>
    <script src="static/js/bulma-slider.min.js"></script>
    <script src="static/js/index.js"></script>
</head>

<body>

    <!-- Navbar -->
    <section class="hero">
        <div class="hero-body">
            <div class="container is-fullhd">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Look, Focus, Act:<br/>Efficient and Robust Robot Learning
                            via Human Gaze and Foveated Vision Transformers</h1>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a target="_blank" href="https://ian-chuang.github.io/">Ian Chuang</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://andrewcwlee.github.io/">Andrew Lee</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="https://www.linkedin.com/in/gao-dechen/">Dechen
                                    Gao</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank" href="">Jinyu Zou</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a target="_blank"
                                    href="https://soltanilab.engineering.ucdavis.edu/people/iman-soltani">Iman
                                    Soltani</a><sup>2</sup>,
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>University of California, Berkeley </span>
                            <span class="author-block"><sup>2</sup>University of California, Davis</span>
                            <span class="author-block"><sup>3</sup>Tongji University</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">

                                <!-- Arxiv PDF link -->
                                <!-- <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2409.17435" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span> -->

                                <!-- Github link -->
                                <span class="link-block">
                                    <a href="" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code (Coming Soon)</span>
                                    </a>
                                </span>

                                <!-- Github link -->
                                <span class="link-block">
                                    <a href="https://github.com/Soltanilara/av-aloha-unity/tree/eye-tracking"
                                        target="_blank" class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-unity"></i>
                                        </span>
                                        <span>VR Unity Code</span>
                                    </a>
                                </span>

                                <!-- ArXiv abstract Link -->
                                <!-- <span class="link-block">
                                    <a href="https://arxiv.org/abs/2409.17435" target="_blank"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span> -->
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Video Teaser -->
    <!-- <section class="hero teaser">
        <div class="container is-fullhd">
            <div class="hero-body">
                <div class="container">
                    <div class="columns is-vcentered  is-centered">
                        <div class="publication-video">
                            <iframe src="https://www.youtube.com/embed/DwJzdaKM4N0" frameborder="0"
                                allow="autoplay; encrypted-media" allowfullscreen></iframe>
                        </div>
                        </br>
                    </div>
                    <br>
                    <h2 class="subtitle has-text-centered">
                        <span class="dperact">We introduce <b>AV-ALOHA</b>, a bimanual robot system with <b>7-DoF active
                                vision</b> that is an extension of <a href="https://aloha-2.github.io/">ALOHA 2</a>.
                            This system offers an immersive teleoperation experience using VR and serves as a platform
                            to evaluate active vision in imitation learning and manipulation.</span>
                    </h2>
                </div>
            </div>
        </div>
    </section> -->

    <!-- Abstract -->
    <section class="section hero is-light">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Human vision is a highly active process driven by gaze, which directs attention and fixation
                            to task-relevant regions and dramatically reduces visual processing. In contrast, robot
                            learning systems typically rely on passive, uniform processing of raw camera images. In this
                            work, we explore how incorporating human-like active gaze into robotic policies can enhance
                            both efficiency and performance. We build on recent advances in foveated image processing
                            and apply them to an Active Vision robot system that emulates both human head movement and
                            eye tracking. Extending prior work on the AV-ALOHA robot simulation platform, we introduce a
                            framework for simultaneously collecting eye-tracking data and robot demonstrations from a
                            human operator as well as a simulation benchmark and dataset for training robot policies
                            that incorporate human gaze. Given the widespread use of Vision Transformers (ViTs) in robot
                            learning, we integrate gaze information into ViTs using a foveated patch tokenization scheme
                            inspired by recent work in image segmentation. Compared to uniform patch tokenization, this
                            significantly reduces the number of tokens—and thus computation—without sacrificing visual
                            fidelity near regions of interest. We also explore two approaches to gaze imitation and
                            prediction from human data. The first is a structured, hierarchical two-stage model that
                            first predicts gaze, which is then used to guide foveation and action prediction. The second
                            is a novel method that treats gaze as an extension of whole-body control, integrating it
                            into the robot’s action space such that the policy directly predicts both future gaze and
                            actions in an end-to-end manner. Our results show that our method for foveated robot vision
                            not only drastically reduces computational overhead, but also improves performance for high
                            precision tasks and robustness to unseen distractors. Together, these findings suggest that
                            human-inspired visual processing offers a useful inductive bias for robotic vision systems.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- System Diagram -->
    <!-- <section class="section hero">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">AV-ALOHA</h2>

                    <img src="static/images/ActiveVisionSystemFigure.png" class="interpolation-image" />
                    <br />
                    <br />

                    <div class="content has-text-justified">

                        <p>
                            The AV-ALOHA system enables intuitive data collection using a VR headset for AV and either
                            VR controllers or leader arms for manipulation. This helps capture full body and head
                            movements to teleoperate both our real and simulation system that record video from six
                            different cameras and provide training data for our AV imitation learning policies.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section> -->

    <!-- <section class="section hero is-light">
        <div class="container is-max-widescreen">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Results</h2>
                    <img src="static/images/ActiveVisionResults.png" class="interpolation-image" />
                    <br />
                    <br />

                    <div class="content has-text-justified">

                        <p>
                            We collect data and run experiments in both real-world and simulation across a variety of
                            tasks that emphasize viewpoint planning. We evaluate the imitation learning policy, <a
                                href="https://tonyzhaozh.github.io/aloha/">ACT</a>, with different camera configurations
                            with and without active vision. Our results show that active vision can significantly
                            improve the performance of imitation learning when there are occlusions or limited
                            visibility.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section> -->

    <!-- Video carousel -->
    <!-- <section class="hero is-small">
        <div class="hero-body">
            <div class="container">
                <h2 class="title is-3">Autonomous Rollouts</h2>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-video1">
                        <video poster="" id="video1" autoplay controls muted loop height="100%">
                            <source src="static/videos/eval_real_occluded_insertion_overhead_cam.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Occluded Insertion
                        </h2>
                    </div>
                    <div class="item item-video2">
                        <video poster="" id="video2" autoplay controls muted loop height="100%">
                            <source src="static/videos/eval_sim_thread_needle_overhead_cam.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Thread Needle
                        </h2>
                    </div>
                    <div class="item item-video3">
                        <video poster="" id="video3" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_sim_tube_transfer_overhead_cam.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Tube Transfer
                        </h2>
                    </div>
                    <div class="item item-video4">
                        <video poster="" id="video4" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_sim_slot_insertion_overhead_cam.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Slot Insertion
                        </h2>
                    </div>
                    <div class="item item-video5">
                        <video poster="" id="video5" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_sim_peg_insertion_overhead_cam.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Peg Insertion
                        </h2>
                    </div>
                    <div class="item item-video6">
                        <video poster="" id="video6" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_sim_hook_package_overhead_cam.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Hook Package
                        </h2>
                    </div>
                    <div class="item item-video7">
                        <video poster="" id="video7" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_real_hidden_pick_overhead_cam.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Hidden Pick
                        </h2>
                    </div>
                </div>
            </div>
        </div>
    </section> -->
    <!-- End video carousel -->

    <!-- Video carousel -->
    <!-- <section class="hero is-small is-light">
        <div class="hero-body">
            <div class="container">
                <h2 class="title is-3">Autonomous Rollouts (Active Vision Camera)</h2>
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-video1">
                        <video poster="" id="video1" autoplay controls muted loop height="100%">
                            <source src="static/videos/eval_real_occluded_insertion_zed_cam_left.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Occluded Insertion
                        </h2>
                    </div>
                    <div class="item item-video2">
                        <video poster="" id="video2" autoplay controls muted loop height="100%">
                            <source src="static/videos/eval_sim_thread_needle_zed_cam_left.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Thread Needle
                        </h2>
                    </div>
                    <div class="item item-video3">
                        <video poster="" id="video3" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_sim_tube_transfer_zed_cam_left.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Tube Transfer
                        </h2>
                    </div>
                    <div class="item item-video4">
                        <video poster="" id="video4" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_sim_slot_insertion_zed_cam_left.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Slot Insertion
                        </h2>
                    </div>
                    <div class="item item-video5">
                        <video poster="" id="video5" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_sim_peg_insertion_zed_cam_left.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Peg Insertion
                        </h2>
                    </div>
                    <div class="item item-video6">
                        <video poster="" id="video6" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_sim_hook_package_zed_cam_left.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Hook Package
                        </h2>
                    </div>
                    <div class="item item-video7">
                        <video poster="" id="video7" autoplay controls muted loop height="100%">\
                            <source src="static/videos/eval_real_hidden_pick_zed_cam_left.mp4" type="video/mp4">
                        </video>
                        <h2 class="subtitle has-text-centered">
                            Hook Package
                        </h2>
                    </div>
                </div>
            </div>
        </div>
    </section> -->
    <!-- End video carousel -->


    <!--BibTex citation -->
    <!-- <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@misc{chuang2024activevisionneedexploring,
    title={Active Vision Might Be All You Need: Exploring Active Vision in Bimanual Robotic Manipulation}, 
    author={Ian Chuang and Andrew Lee and Dechen Gao and Iman Soltani},
    year={2024},
    eprint={2409.17435},
    archivePrefix={arXiv},
    primaryClass={cs.RO},
    url={https://arxiv.org/abs/2409.17435}, 
}</code></pre>
        </div>
    </section> -->
    <!--End BibTex citation -->


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">

                        <p>
                            This page was built using the <a
                                href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
                            You are free to borrow the source code of this website, we just ask that you link back to
                            this page in the footer. <br> This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>

                    </div>
                </div>
            </div>
        </div>
    </footer>



</body>

</html>